{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a82fa2b-1a76-40a5-9df0-00b7facc2010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Solving Classification problems using Logistic Regression\n",
    "\n",
    "# getting the Titanic dataset\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(r'C:\\Users\\maria\\Downloads\\Project Data\\titanic\\train.csv') \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfc870c7-9b31-47a8-82af-5b12f75563b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns that are not useful to us\n",
    "df = df.drop('PassengerId', axis=1) \n",
    "# axis=1 means column\n",
    "df = df.drop('Name',        axis=1)\n",
    "df = df.drop('Ticket',      axis=1)\n",
    "df = df.drop('Cabin',       axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230290f-2e81-4b97-b47c-815e10fb1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "df = df.dropna()               # drop all rows \n",
    "                               # with NaN\n",
    "df = df.reset_index(drop=True) # re-index the \n",
    "                               # dataframe\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919fd32d-c606-4e93-8e23-bc670034d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Non-Numeric Fields\n",
    "\n",
    "# initialize label encoder\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# convert Sex and Embarked features to numeric\n",
    "sex_encoded = label_encoder.fit_transform(df[\"Sex\"])\n",
    "print(sex_encoded)\n",
    "# 0 = female\n",
    "# 1 = male\n",
    "df['Sex'] = sex_encoded\n",
    "embarked_encoded = label_encoder.fit_transform(df[\"Embarked\"])\n",
    "print(embarked_encoded)\n",
    "# 0 = C\n",
    "# 1 = Q\n",
    "# 2 = S\n",
    "df['Embarked'] = embarked_encoded\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d55c7a-f89d-49f6-bd9c-ac7722cbdfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Fields Categorical\n",
    "df[\"Pclass\"]   = pd.Categorical(df[\"Pclass\"])\n",
    "df[\"Sex\"]      = pd.Categorical(df[\"Sex\"])\n",
    "df[\"Embarked\"] = pd.Categorical(df[\"Embarked\"])\n",
    "df[\"Survived\"] = pd.Categorical(df[\"Survived\"])\n",
    "print(df.dtypes)    # examine the datatypes \n",
    "                    # for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf32e1-c752-46ea-b83e-ca37c3cf9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Dataset into Train and Test Sets\n",
    "\n",
    "# use all columns except Survived as features for training\n",
    "features = df.drop('Survived', axis=1)\n",
    "\n",
    "# the label is Survived\n",
    "label = df['Survived']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into train and test sets\n",
    "train_features,test_features, train_label,test_label = train_test_split(\n",
    "        features,\n",
    "        label,\n",
    "        test_size = 0.25, # split ratio\n",
    "        random_state = 1, # Set random seed \n",
    "        stratify = df[\"Survived\"])\n",
    "\n",
    "# training set\n",
    "print(train_features.head())\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161104b-0eef-471a-a4c8-96c66cb4f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set for validation\n",
    "print(test_features.head())\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6faecf-a75b-4eea-b3d0-1018c4dacffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "\n",
    "# initialize logistic regression model\n",
    "log_regress = linear_model.LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "log_regress.fit(X = train_features,\n",
    "                y = train_label)\n",
    "\n",
    "# check trained model intercept\n",
    "print(log_regress.intercept_)\n",
    "\n",
    "# check trained model coefficients\n",
    "print(log_regress.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6be4b-850f-455b-95ff-d6f3a59adf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "preds = log_regress.predict(X=test_features)\n",
    "print(preds)\n",
    "\n",
    "# Predict the probablities\n",
    "pred_probs = log_regress.predict_proba(X=test_features) \n",
    "print(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5653b51-09b0-4fb9-9408-6b0b4cd0de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the Metrics\n",
    "\n",
    "# Generate table of predictions vs actual\n",
    "print(pd.crosstab(preds, test_label))\n",
    "\n",
    "# get the accuracy of the prediction\n",
    "log_regress.score(X = test_features , y = test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132a49f-ec9c-4f0e-8098-ef8c20015f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# view the confusion matrix\n",
    "metrics.confusion_matrix(\n",
    "    y_true = test_label,    # True labels\n",
    "    y_pred = preds)         # Predicted labels\n",
    "\n",
    "# View summary of common classification metrics\n",
    "print(metrics.classification_report(\n",
    "      y_true = test_label,\n",
    "      y_pred = preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
